{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'unidecode'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 9\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mglob\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01munidecode\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m unidecode\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'unidecode'"
     ]
    }
   ],
   "source": [
    "import urllib.request,sys,time\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import os.path\n",
    "import glob\n",
    "import os\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "page 1\n",
      "2\n",
      "page 2\n",
      "3\n",
      "page 3\n",
      "4\n",
      "page 4\n",
      "5\n",
      "page 5\n",
      "6\n",
      "page 6\n",
      "7\n",
      "finished\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "def extract_news(start_date = '1402/07/01',end_date = '1402/08/01',service_id=0,section_id=0,subject_id = 0):\n",
    "    page_number = 1\n",
    "    url = 'https://www.asriran.com/fa/archive?service_id='+str(service_id)+'&sec_id='+str(section_id)+'&cat_id='+str(subject_id)+'&rpp=100&from_date='+start_date+'&to_date='+end_date+'&p='\n",
    "    while True:\n",
    "\n",
    "        if (os.path.isfile('.\\\\data'+str(page_number)+'.csv')):\n",
    "            print('there is already page '+str(page_number))\n",
    "            page_number += 1\n",
    "            continue\n",
    "\n",
    "\n",
    "        print(page_number)\n",
    "        upperframe=[] \n",
    "        url1 = url + str(page_number)\n",
    "        page = requests.get(url1)\n",
    "        # print(page.text)\n",
    "        soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "        # print(page.text)\n",
    "        # with open('output'+str(page_number)+'.html', \"w\",encoding=\"utf-8\") as file:\n",
    "        #     file.write(str(soup))\n",
    "\n",
    "\n",
    "        articles=soup.find_all('article',attrs={'vizhe_cv col-xs-12 col-sm-6'})\n",
    "        if len(articles)==0 :\n",
    "            print('finished')\n",
    "            break\n",
    "        print('page '+ str(page_number))\n",
    "       \n",
    "        for article in articles:\n",
    "            title = article.find(\"a\",attrs={'class':\"vizhe_title\"}).text.strip()\n",
    "            link = article.find(\"a\").get('href').strip()\n",
    "            link = 'https://www.asriran.com' + link\n",
    "\n",
    "            summary = article.find(\"div\",attrs={'class':\"vizhe_lead\"}).text.strip()\n",
    "            date = article.find(\"span\",attrs={'class':\"tarikh_archive\"}).text.strip()\n",
    "\n",
    "            url2 = link\n",
    "            page2 = requests.get(url2)\n",
    "            soup2 = BeautifulSoup(page2.text, \"html.parser\")\n",
    "\n",
    "\n",
    "            # IF THE PAGE IS GONE\n",
    "            ERROR = soup2.find(\"div\",attrs={'class':\"error_container\"})\n",
    "            if ERROR :\n",
    "                subject = ''\n",
    "                body = 'صفحه درخواستی شما موجود نمی باشد'\n",
    "                news_id = ''\n",
    "                short_link = ''\n",
    "                img_path=''\n",
    "                tag_word=''\n",
    "                frame = [news_id,date,subject,title,summary,body,short_link,img_path,tag_word]\n",
    "                upperframe.append(frame)\n",
    "                continue # jump to the next article\n",
    "\n",
    "\n",
    "            subject = soup2.find(\"div\",attrs={'class':\"news_path\"}).find_all(\"a\")[-1].text\n",
    "            # if  (subject != None):\n",
    "                # subject = subject.find_all(\"a\")[-1].text\n",
    "\n",
    "            # body = soup2.find(\"div\",attrs={'class':\"body\"}).text.strip()[:-155]\n",
    "            body = soup2.find(\"div\",attrs={'class':\"body\"}).text.strip()[:-155]\n",
    "            # if  (body != None):\n",
    "            #     body = body.text.strip()[:-155]\n",
    "\n",
    "            img_path = soup2.find(\"img\",attrs={'class':\"lead_image\"})\n",
    "            if  (img_path != None):\n",
    "                img_path = img_path.get('src').strip()\n",
    "\n",
    "            news_id = soup2.find(\"div\",attrs={'class':\"news_nav news_id_c\"}).text.strip()\n",
    "            news_id = int(re.findall(r'\\d+', news_id)[0])\n",
    "            news_id = (str(news_id))\n",
    "            # if  (news_id != None):\n",
    "                # news_id = news_id.text.strip()\n",
    "\n",
    "                # news_id = int(re.findall(r'\\d+', news_id)[0])\n",
    "                # news_id = (str(news_id))\n",
    "                # news_id = unidecode(u\"۰۱۲۳۴۵۶۷۸۹\")\n",
    "\n",
    "            tags_list = []\n",
    "            tags_items = soup2.find_all(\"a\", class_=\"tags_item\")\n",
    "            if tags_items:\n",
    "                for tag_item in tags_items:\n",
    "                    tag_text = tag_item.get_text(strip=True)\n",
    "                    tags_list.append(tag_text)\n",
    "\n",
    "            short_link = \"\"\n",
    "            if soup2.find(\"div\",attrs={'class':\"short-link row\"}).find(\"a\"):\n",
    "                short_link = soup2.find(\"div\",attrs={'class':\"short-link row\"}).find(\"a\").get('href').strip()\n",
    "                short_link = 'https://www.asriran.com' + short_link\n",
    "\n",
    "            # df = pd.DataFrame(columns=['tags'])\n",
    "            #\n",
    "            # # Append the list of tags to the DataFrame\n",
    "            # df['tags'] = [tags_list]\n",
    "            \n",
    "            frame = [news_id,date,subject,title,summary,body,short_link,img_path,tags_list]\n",
    "            upperframe.append(frame)\n",
    "            # upperframe[-1].append(tags_list)\n",
    "\n",
    "        data=pd.DataFrame(upperframe, columns=['News_ID','Date','Subject','Title','Summary','Body','Short_link','img_path','tag_list'])\n",
    "        data.to_csv('data'+str(page_number)+'.csv', encoding='utf-8', index=False)\n",
    "        page_number += 1\n",
    "\n",
    "    #data=pd.DataFrame(upperframe, columns=['News_ID','Date','Subject','Title','Summary','Body','Short_link'])\n",
    "\n",
    "    return print(\"DONE\")\n",
    "\n",
    "extract_news(start_date = '1402/07/28',end_date = '1402/08/01',service_id=0,section_id=0,subject_id = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the path for joining multiple files\n",
    "#files = os.path.join(\".\\\\\", \"data*.csv\")\n",
    "# https://sparkbyexamples.com/pandas/pandas-read-multiple-csv-files/\n",
    "\n",
    "# list of merged files returned\n",
    "files = glob.glob('.\\\\data*.csv')\n",
    "\n",
    "# joining files with concat and read_csv\n",
    "df = pd.concat(map(pd.read_csv, files), ignore_index=True)\n",
    "\n",
    "# convert df to csv\n",
    "df.to_csv('data.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   News_ID        Date    Subject  \\\n0   912803  ۱۴۰۲/۰۸/۰۱   اجتماعی    \n1   912802  ۱۴۰۲/۰۸/۰۱  بین الملل   \n2   912801  ۱۴۰۲/۰۸/۰۱   اجتماعی    \n3   912800  ۱۴۰۲/۰۸/۰۱  بین الملل   \n4   912799  ۱۴۰۲/۰۸/۰۱      سیاسی   \n\n                                               Title  \\\n0                بیشترین جستجوی گوگل ایرانیان در مهر   \n1  بایدن : گفت‌وگو برای آتش‌ بس میان حماس و اسرائ...   \n2  کنکور اختصاصی تربیت معلم اردیبهشت ۱۴۰۳ برگزار ...   \n3                      حماس دو اسیر دیگر را آزاد کرد   \n4  امیرعبداللهیان: آمریکا به ایران پیام داده و گف...   \n\n                                             Summary  \\\n0  مهر امسال، عجیب بود. مرگ سه هنرمند باعث شد که ...   \n1  بایدن در کنفرانسی خبری در پاسخ به سوالی در راب...   \n2  در اردیبهشت ۱۴۰۳ برای اولین بار کنکور تربیت مع...   \n3  رویترز نوشت که این خبر توسط گردان القسام - از ...   \n4  وزیر امور خارجه: آقای بایدن ریاکاری را متوقف ک...   \n\n                                                Body  \\\n0  کانال عصر ایران در تلگرام                     ...   \n1  جو بایدن، رئیس‌جمهوری آمریکا گفت‌وگو برای حصول...   \n2  وزیر آموزش و پرورش در جلسه هیأت امنای دانشگاه ...   \n3  حماس امروز (دوشنبه) از آزادی دو اسیر دیگر خبر ...   \n4  حسین امیرعبداللهیان درباره پیام آمریکا به ایرا...   \n\n                       Short_link  \\\n0  https://www.asriran.com/003pSd   \n1  https://www.asriran.com/003pSc   \n2  https://www.asriran.com/003pSb   \n3  https://www.asriran.com/003pSa   \n4  https://www.asriran.com/003pSZ   \n\n                                            img_path  \\\n0  https://cdn.asriran.com/files/fa/news/1402/8/1...   \n1  https://cdn.asriran.com/files/fa/news/1402/8/1...   \n2  https://cdn.asriran.com/files/fa/news/1402/8/1...   \n3  https://cdn.asriran.com/files/fa/news/1402/8/1...   \n4  https://cdn.asriran.com/files/fa/news/1402/8/1...   \n\n                     tag_list  \n0        ['گوگل', 'ایرانیان']  \n1            ['بایدن', 'غزه']  \n2           ['کنکور', 'معلم']  \n3  ['حماس', 'آمریکا', 'اسیر']  \n4         ['آمریکا', 'ایران']  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>News_ID</th>\n      <th>Date</th>\n      <th>Subject</th>\n      <th>Title</th>\n      <th>Summary</th>\n      <th>Body</th>\n      <th>Short_link</th>\n      <th>img_path</th>\n      <th>tag_list</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>912803</td>\n      <td>۱۴۰۲/۰۸/۰۱</td>\n      <td>اجتماعی</td>\n      <td>بیشترین جستجوی گوگل ایرانیان در مهر</td>\n      <td>مهر امسال، عجیب بود. مرگ سه هنرمند باعث شد که ...</td>\n      <td>کانال عصر ایران در تلگرام                     ...</td>\n      <td>https://www.asriran.com/003pSd</td>\n      <td>https://cdn.asriran.com/files/fa/news/1402/8/1...</td>\n      <td>['گوگل', 'ایرانیان']</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>912802</td>\n      <td>۱۴۰۲/۰۸/۰۱</td>\n      <td>بین الملل</td>\n      <td>بایدن : گفت‌وگو برای آتش‌ بس میان حماس و اسرائ...</td>\n      <td>بایدن در کنفرانسی خبری در پاسخ به سوالی در راب...</td>\n      <td>جو بایدن، رئیس‌جمهوری آمریکا گفت‌وگو برای حصول...</td>\n      <td>https://www.asriran.com/003pSc</td>\n      <td>https://cdn.asriran.com/files/fa/news/1402/8/1...</td>\n      <td>['بایدن', 'غزه']</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>912801</td>\n      <td>۱۴۰۲/۰۸/۰۱</td>\n      <td>اجتماعی</td>\n      <td>کنکور اختصاصی تربیت معلم اردیبهشت ۱۴۰۳ برگزار ...</td>\n      <td>در اردیبهشت ۱۴۰۳ برای اولین بار کنکور تربیت مع...</td>\n      <td>وزیر آموزش و پرورش در جلسه هیأت امنای دانشگاه ...</td>\n      <td>https://www.asriran.com/003pSb</td>\n      <td>https://cdn.asriran.com/files/fa/news/1402/8/1...</td>\n      <td>['کنکور', 'معلم']</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>912800</td>\n      <td>۱۴۰۲/۰۸/۰۱</td>\n      <td>بین الملل</td>\n      <td>حماس دو اسیر دیگر را آزاد کرد</td>\n      <td>رویترز نوشت که این خبر توسط گردان القسام - از ...</td>\n      <td>حماس امروز (دوشنبه) از آزادی دو اسیر دیگر خبر ...</td>\n      <td>https://www.asriran.com/003pSa</td>\n      <td>https://cdn.asriran.com/files/fa/news/1402/8/1...</td>\n      <td>['حماس', 'آمریکا', 'اسیر']</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>912799</td>\n      <td>۱۴۰۲/۰۸/۰۱</td>\n      <td>سیاسی</td>\n      <td>امیرعبداللهیان: آمریکا به ایران پیام داده و گف...</td>\n      <td>وزیر امور خارجه: آقای بایدن ریاکاری را متوقف ک...</td>\n      <td>حسین امیرعبداللهیان درباره پیام آمریکا به ایرا...</td>\n      <td>https://www.asriran.com/003pSZ</td>\n      <td>https://cdn.asriran.com/files/fa/news/1402/8/1...</td>\n      <td>['آمریکا', 'ایران']</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "4376"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of articles\n",
    "len(df. index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def get_unique_values(csv_file_path, column_name):\n",
    "    unique_values = set()\n",
    "    with open(csv_file_path, 'r', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            unique_values.add(row[column_name])\n",
    "    return list(unique_values)\n",
    "\n",
    "# Example usage\n",
    "csv_file_path = 'data.csv'\n",
    "column_name = 'Subject'\n",
    "unique_subjects = get_unique_values(csv_file_path, column_name)\n",
    "print(unique_subjects)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "37ee99bff104f98bd1f5372e2ee364e0f3435400cb3778afef49450308d28634"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
